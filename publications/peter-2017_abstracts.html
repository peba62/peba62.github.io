
<dl>

<dt>
<a name="Baumgartner:etal:tableaux-policy-synthesis-long:2017">&nbsp;</a>
</dt>
<dd>
Peter Baumgartner, Sylvie Thi&eacute;baux, and Felipe Trevizan.<br>
 <b>Tableaux for Policy Synthesis for MDPs with PCTL*
  Constraints</b>.<br>
 <em>CoRR</em>, abs/1706.10102, 2017.
[&nbsp;<a href="peter-2017_bib.html#Baumgartner:etal:tableaux-policy-synthesis-long:2017">bib</a>&nbsp;| 
<a href="https://arxiv.org/abs/1706.10102">http</a>&nbsp;]
<blockquote><font size="-1">
Markov decision processes (MDPs) are the standard formalism for
                  modelling sequential decision making in stochastic
                  environments. Policy synthesis addresses the problem of how
                  to control or limit the decisions an agent makes so that a
                  given specification is met. In this paper we consider PCTL*,
                  the probabilistic counterpart of CTL*, as the specification
                  language. Because in general the policy synthesis problem
                  for PCTL* is undecidable, we restrict to policies whose
                  execution history memory is finitely bounded a priori.
                  Surprisingly, no algorithm for policy synthesis for this
                  natural and expressive framework has been developed so
                  far. We close this gap and describe a tableau-based
                  algorithm that, given an MDP and a PCTL* specification,
                  derives in a non-deterministic way a system of (possibly
                  nonlinear) equalities and inequalities. The solutions of
                  this system, if any, describe the desired (stochastic)
                  policies.  Our main result in this paper is the correctness
                  of our method, i.e., soundness, completeness and
                  termination.
</font></blockquote>

</dd>


<dt>
<a name="Baumgartner:etal:tableaux-policy-synthesis:TABLEAUX:2017">&nbsp;</a>
</dt>
<dd>
Peter Baumgartner, Sylvie Thi&eacute;baux, and Felipe Trevizan.<br>
 <b>Tableaux for Policy Synthesis for MDPs with PCTL*
  Constraints</b>.<br>
 In Renate&nbsp;A. Schmidt and Cl&aacute;udia Nalon, editors, <em>Tableaux
  2017 -- Automated Reasoning with Analytic Tableaux and Related Methods</em>,
  volume 10501 of <em>Lecture Notes in Artificial Intelligence</em>, pages
  175--192. Springer, 2017.<br>
 Copyright Springer Verlag
  <a href="http://www.springer.de/comp/lncs/index.html">http://www.springer.de/comp/lncs/index.html</a>.
[&nbsp;<a href="peter-2017_bib.html#Baumgartner:etal:tableaux-policy-synthesis:TABLEAUX:2017">bib</a>&nbsp;| 
<a href="policy-synthesis-tableaux.pdf">.pdf</a>&nbsp;]
<blockquote><font size="-1">
Markov decision processes (MDPs) are the standard formalism for
modelling sequential decision making in stochastic environments. Policy
synthesis addresses the problem of how to control or limit the decisions an
agent makes so that a given specification is met. In this paper we
consider PCTL*, the probabilistic counterpart of CTL*, as the specification
language. Because in general the policy synthesis problem for
PCTL* is undecidable, we restrict to policies whose execution history memory
is finitely bounded a priori.
Surprisingly, no algorithm for policy synthesis for this natural and
expressive framework has been developed so far.  We close this gap and
describe a tableau-based algorithm that, given an MDP and a PCTL* specification, derives
in a non-deterministic way a system of (possibly nonlinear) equalities
and inequalities. The solutions of this system, if any, describe the
desired (stochastic) policies.
Our main result in this paper is the correctness of our method, i.e.,
soundness, completeness and termination.
</font></blockquote>

</dd>
</dl>